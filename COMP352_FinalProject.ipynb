{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04ee06c",
   "metadata": {},
   "source": [
    "# COMP 352 Final Project - Spotify Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca52da",
   "metadata": {},
   "source": [
    "### By Cameron McNamara, Bilal Adam, Maximo Babun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703fc22a",
   "metadata": {},
   "source": [
    "Requirements: \n",
    "  - There are four sections of the final project. You are expected to perform the following tasks within each section to fulfill the project requirements. Remember data science is cyclical in nature and requires multiple attempts and iterations. It is okay if your code moves between sections as you try different approaches, but at the end please try and organize your code into these sections for grading purposes.\n",
    "- Data Importing and Pre-processing (100 Points)\n",
    "  - Import dataset and describe characteristics such as dimensions, data types, file types, and import methods used\n",
    "  - Clean, wrangle, and handle missing data, duplicate data, etc.\n",
    "  - Encode any categorical variables\n",
    "  - Perform feature engineering on the dataset\n",
    "  - Transform data appropriately using techniques such as aggregation, normalization, and feature construction\n",
    "  - Reduce redundant data and perform need based discretization\n",
    "- Data Analysis and Visualization (100 Points)\n",
    "  - Identify categorical, ordinal, and numerical variables within data\n",
    "  - Provide measures of centrality and distribution with visualizations\n",
    "  - Diagnose for correlations between variables and determine independent and dependent variables\n",
    "  - Perform exploratory analysis in combination with visualization techniques to discover patterns and features of interest\n",
    "  - Create visualizations that allow for the discovery of insights in the data\n",
    "\n",
    "- Data Analytics (100 Points)\n",
    "  - Determine the need for a supervised or unsupervised learning method and identify dependent and independent variables\n",
    "  - Choose and provide reasoning for the selected metric or metrics employed to assess your model.\n",
    "  - Train, test, cross validate, and provide performance metrics for model results\n",
    "  - Try multiple different types of algorithms to determine the best model for your dataset\n",
    "  - Analyze your model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c66d1",
   "metadata": {},
   "source": [
    "First we must setup our environment to make sure we have all appropriate modules installed. To do this, I have provided 2 methods. The 1st, is to install all modules using a ```.yaml``` file via ```conda```. \n",
    "\n",
    "To do this, run:\n",
    "```bash\n",
    "conda env create -f env_setup/data_environment.yml\n",
    "```\n",
    "Then activate the environment by:\n",
    "```bash\n",
    "conda activate data_env\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc52e26a",
   "metadata": {},
   "source": [
    "## Data Importing and Pre-processing <a class=\"anchor\" id=\"data-importing\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e256522",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeRegressor\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     26\u001b[39m     time_series_split_regression,\n\u001b[32m     27\u001b[39m     StackedEnsembleCVRegressor,\n\u001b[32m     28\u001b[39m )\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     30\u001b[39m     compute_rmse_std,\n\u001b[32m     31\u001b[39m     print_rmse_and_dates,\n\u001b[32m     32\u001b[39m )\n\u001b[32m     34\u001b[39m warnings.filterwarnings(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# import libraries needed\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import warnings\n",
    "\n",
    "import branca\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from branca.element import Figure\n",
    "from folium import Marker\n",
    "from folium.plugins import HeatMap\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import norm, probplot, skew\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from utils.model_utils import (\n",
    "    time_series_split_regression,\n",
    "    StackedEnsembleCVRegressor,\n",
    ")\n",
    "from utils.metrics_utils import (\n",
    "    compute_rmse_std,\n",
    "    print_rmse_and_dates,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas.*\")\n",
    "%matplotlib inline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
